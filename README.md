# awesome-multimodal-dialogue
Paper, dataset and code list for multimodal dialogue.

W.I.P

Feel free to open issues and make PRs!


## Datasets
- [Visual Dialog](https://arxiv.org/abs/1611.08669), CVPR 2017, [[data]](https://visualdialog.org/)[[code]](https://github.com/batra-mlp-lab/visdial)
- [Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation](https://aclanthology.org/I17-1047.pdf), IJCNLP 2017, [[data]](https://www.microsoft.com/en-us/download/details.aspx?id=55324&751be11f-ede8)
- [MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations](https://aclanthology.org/P19-1050.pdf), ACL 2019 (arXiv 2018), [[data]](https://affective-meld.github.io/)[[code]](https://github.com/declare-lab/MELD/)
- [Image-Chat: Engaging Grounded Conversations](https://aclanthology.org/2020.acl-main.219.pdf), ACL 2020 (arXiv 2018), [[data & code]](https://parl.ai/projects/image_chat/)
- [OpenViDial: A Large-Scale, Open-Domain Dialogue Dataset with Visual Context](https://arxiv.org/pdf/2012.15015.pdf), arXiv 2020, [[data & code]](https://github.com/ShannonAI/OpenViDial)
- [OpenViDial 2.0: A Larger-Scale, Open-Domain Dialogue Generation Dataset with Visual Contexts](https://arxiv.org/pdf/2109.12761.pdf), arXiv 2021, [[data & code]](https://github.com/ShannonAI/OpenViDial)
- [MMChat: Multi-Modal Chat Dataset on Social Media](https://aclanthology.org/2022.lrec-1.621.pdf), LREC 2022 (arXiv 2021), [[data & code]](https://github.com/silverriver/MMChat)
- [Towards Expressive Communication with Internet Memes: A New Multimodal Conversation Dataset and Benchmark](https://arxiv.org/pdf/2109.01839.pdf), arXiv 2021, [[data & code]](https://github.com/lizekang/DSTC10-MOD)
- [PhotoChat: A Human-Human Dialogue Dataset with Photo Sharing Behavior for Joint Image-Text Modeling](https://aclanthology.org/2021.acl-long.479.pdf), ACL 2021, [[data]](https://github.com/google-research/google-research/tree/master/multimodalchat/)
- [MSCTD: A Multimodal Sentiment Chat Translation Dataset](https://aclanthology.org/2022.acl-long.186.pdf), ACL 2022, [[data & code]](https://github.com/XL2248/MSCTD)
- [M3ED: Multi-modal Multi-scene Multi-label Emotional Dialogue Database](https://aclanthology.org/2022.acl-long.391.pdf), ACL 2022, [[data & code]](https://github.com/aim3-ruc/rucm3ed)
